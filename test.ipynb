{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database_utils import DatabaseConnector as dc\n",
    "from data_extraction import DataExtractor as dex\n",
    "from data_cleaning import DataCleaning as dcl\n",
    "\n",
    "import pandas as pd\n",
    "import nbformat # save as .ipynb\n",
    "\n",
    "import yaml # to read .yaml. Help with read_db_creds\n",
    "from sqlalchemy import create_engine, inspect # this ORM will transform the python objects into SQL tables\n",
    "from decouple import config #  calling sensitive information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='db_creds.yaml' # Step 1: Specify the correct file path\n",
    "database_connector = dc()\n",
    "credentials = database_connector.read_db_creds(file_path)    # Step 2: Read credentials\n",
    "engine = database_connector.init_db_engine(credentials)      # Step 3: Initialise database engine\n",
    "data_extractor = dex()\n",
    "\n",
    "# Rest of your code for extracting data and saving the notebook\n",
    "tables = data_extractor.list_db_tables(engine)   \n",
    "# Available Tables: ['legacy_store_details', 'legacy_users', 'orders_table']            \n",
    "print(\"Available Tables: \", tables)                          # Step 4: List all tables in the database\n",
    "for table_name in tables:\n",
    "\n",
    "    # Import data from the table into DataFrame\n",
    "    table_df = pd.read_sql(table_name, engine)\n",
    "\n",
    "    # Save the DataFrame as a CSV file\n",
    "    csv_filename = f\"{table_name}_data.csv\"\n",
    "    table_df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Saved {table_name} DataFrame as {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a regular expression pattern\n",
    "integer_pattern = re.compile(r'\\d+')\n",
    "\n",
    "# Example values as a list\n",
    "values = ['80r', 'rt78', '101']\n",
    "\n",
    "# Iterate over each element in the list\n",
    "for value in values:\n",
    "    # Use search method to find the first match of the pattern in the string\n",
    "    match = integer_pattern.search(str(value))\n",
    "\n",
    "    # Check if a match is found\n",
    "    if match:\n",
    "        # Access the matched portion using group()\n",
    "        matched_value = match.group()\n",
    "        print(f\"Original value: {value}\")\n",
    "        print(f\"Matched value: {matched_value}\")\n",
    "        print(matched_value)\n",
    "    else:\n",
    "        print(f\"No match found for {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula # read tables in a PDF\n",
    "\n",
    "\n",
    "def retrieve_pdf_data(pdf_path = \"https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf\"):\n",
    "    card_data_df = tabula.read_pdf(pdf_path, stream=True)\n",
    "    return card_data_df\n",
    "\n",
    "card_data_df = retrieve_pdf_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "database_connector = dc()\n",
    "credentials = database_connector.read_db_creds()  \n",
    "\n",
    "api_key = f\"{credentials['api_key']}\"\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX\n"
     ]
    }
   ],
   "source": [
    "api_key = config('api_key')\n",
    "cred_dict = dc.read_db_creds(file_path = api_key)\n",
    "key = cred_dict['api_key']\n",
    "\n",
    "headers = {'x-api-key': key}\n",
    "\n",
    "print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = config('mypassword')\n",
    "print(password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = config('api_key')\n",
    "print(password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #API section\n",
    "\n",
    "    api_key = config('api_key')\n",
    "    api_connector = dc()\n",
    "    cred_api = api_connector.read_db_creds(file_path = api_key)\n",
    "    x_api_key = cred_api['api_key']\n",
    "\n",
    "    headers = {'x-api-key': x_api_key}\n",
    "\n",
    "    number_of_stores_endpoint = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores'\n",
    "    retrieve_a_store_endpoint = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/{store_number}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 'products_details' as 'products_details.csv'.\n",
      "An error occurred: read_csv() got an unexpected keyword argument 'index'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m s3_address \u001b[38;5;241m=\u001b[39m cred_api[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3_address\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# access the .yaml key\u001b[39;00m\n\u001b[0;32m     27\u001b[0m local_file_path \u001b[38;5;241m=\u001b[39m cred_api[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_file_path\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# specifies the desired local path to save the file\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m products_df, table_name, csv_filename \u001b[38;5;241m=\u001b[39m api_extractor\u001b[38;5;241m.\u001b[39mextract_from_s3(s3_address, local_file_path)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, shall be extracted. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(products_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "from database_utils import DatabaseConnector as dc\n",
    "from data_extraction import DataExtractor as dex\n",
    "from data_cleaning import DataCleaning as dcl\n",
    "# import missingno as msno # Visualising Missing Data\n",
    "# import plotly.express as px # Visualising histogram\n",
    "\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import nbformat # save as .ipynb\n",
    "\n",
    "from decouple import config #  calling sensitive information\n",
    "import yaml # to read .yaml. Help with read_db\n",
    "\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "# Retrieve PDF from AWS S3 bucket and convert to CSV\n",
    "api_extractor = dex() \n",
    "\n",
    "# to gain access to private credentials for API\n",
    "cred_access = config('credentials_env') # refers to .yaml file ## from decouple import config\n",
    "cred_api = api_connector.read_db_creds(file_path = cred_access) # extracts the .yaml file\n",
    "\n",
    "s3_address = cred_api['s3_address'] # access the .yaml key\n",
    "local_file_path = cred_api['local_file_path'] # specifies the desired local path to save the file\n",
    "products_df, table_name, csv_filename = api_extractor.extract_from_s3(s3_address, local_file_path)\n",
    "\n",
    "print(f\"'{table_name}', shall be extracted. \\n\")\n",
    "print(products_df, \"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrdc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
